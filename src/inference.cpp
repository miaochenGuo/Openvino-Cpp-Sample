#include <opencv2/core.hpp>

#include <iostream>
#include <utility>
#include <vector>
#include <map>
#include <memory>
#include <string>
#include <gflags/gflags.h>
#include <ext_list.hpp>


#include <iomanip>
#include <vector>
#include <memory>
#include <string>
#include <cstdlib>

#ifdef UNICODE
#include <tchar.h>
#endif

#include <opencv2/opencv.hpp>
#include <inference_engine.hpp>

#include <caffe/caffe.hpp>
#include <time.h>
#include <ctime>
#include <ctime>
#include <ratio>
#include <chrono>
#include <sys/types.h>
#include <dirent.h>

using namespace std::chrono;
using namespace InferenceEngine;
using namespace std;

using namespace caffe;  // NOLINT(build/namespaces)

#ifndef UNICODE
#define tcout std::cout
#define _T(STR) STR
#else
#define tcout std::wcout
#endif


int main () {
	
	const file_name_t input_model{"/windows/D/workspace/CNN/imaginex/vespa/PETA/vespa-peta_iter_12000_FP16.xml"};
	PluginDispatcher dispatcher({_T("/opt/intel/computer_vision_sdk/inference_engine/lib/ubuntu_18.04/intel64"), _T("")});
	//InferencePlugin plugin (dispatcher.getSuitablePlugin(TargetDevice::eCPU));
	InferencePlugin plugin (dispatcher.getPluginByDevice("MYRIAD"));
	std::string custom_cldnn_kernels;
	plugin.SetConfig({{PluginConfigParams::KEY_CONFIG_FILE, custom_cldnn_kernels}}); 

        //
	// --------------------------- 2. Read IR Generated by ModelOptimizer (.xml and .bin files) ------------
        CNNNetReader network_reader;
        network_reader.ReadNetwork(fileNameToString(input_model));
        network_reader.ReadWeights(fileNameToString(input_model).substr(0, input_model.size() - 4) + ".bin");

        network_reader.getNetwork().setBatchSize(1);
        CNNNetwork network = network_reader.getNetwork();
        
	//std::cout<<"Network batchsize = "<<network_reader.getNetwork().getBatchSize()<<std::endl;

        // -----------------------------------------------------------------------------------------------------
        // --------------------------- 3. Configure input & output ---------------------------------------------
        // --------------------------- Prepare input blobs -----------------------------------------------------
        InputInfo::Ptr input_info = network.getInputsInfo().begin()->second;
        std::string input_name = network.getInputsInfo().begin()->first;

        input_info->setLayout(Layout::NCHW);
        input_info->setPrecision(Precision::U8);

        // --------------------------- Prepare output blobs ----------------------------------------------------
        DataPtr output_info = network.getOutputsInfo().begin()->second;
        std::string output_name = network.getOutputsInfo().begin()->first;

        output_info->setPrecision(Precision::FP32);
        
                // --------------------------- 4. Loading model to the plugin ------------------------------------------
        //ExecutableNetwork executable_network = reid_plugin.LoadNetwork(network, {});
        ExecutableNetwork executable_network = plugin.LoadNetwork(network, {});
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 5. Create infer request -------------------------------------------------
        InferRequest infer_request = executable_network.CreateInferRequest();


	//	/* read mean and subtract it from image */
	caffe::BlobProto blob_proto;
	std::string mean_file = "/home/omair/workspace/CNN/imaginex/vespa/generated/peta_mean.binaryproto";

	cv::Size input_geometry_ = cv::Size(227,227);

	/*caffe::ReadProtoFromBinaryFileOrDie(mean_file.c_str(), &blob_proto);
	caffe::Blob<float> mean_blob;
	mean_blob.FromProto(blob_proto);
	//CHECK_EQ(mean_blob.channels(), num_channels_)<< "Number of channels of mean file doesn't match input layer.";

	std::vector<cv::Mat> channels;
	float* data = mean_blob.mutable_cpu_data();
	for (int i = 0; i < 3; ++i) {
	  cv::Mat channel(mean_blob.height(), mean_blob.width(), CV_32FC1, data);
	  channels.push_back(channel);
	  data += mean_blob.height() * mean_blob.width();
	}
	cv::Mat mean;
	cv::merge(channels, mean); 

	cv::Scalar channel_mean = cv::mean(mean);
	cv::Mat mean_ = cv::Mat(input_geometry_, mean.type(), channel_mean); */


	/* Resize manually and copy data from the image to the input blob */
	InferenceEngine::Blob::Ptr input = infer_request.GetBlob(input_name);
        auto input_data = input->buffer().as<PrecisionTrait<Precision::U8>::value_type *>();		

	size_t channels_number;
	size_t image_size;
    	InferenceEngine::Blob::Ptr output;	
	cv::Mat sample, sample_resized; 
	std::string FolderName = "/windows/D/workspace/CNN/imaginex/vespa/running_vespa_pedestrian_attribute/images/";


	DIR* dirp = opendir(FolderName.c_str());
	struct dirent* dp;

	while((dp = readdir(dirp))!= NULL) {
		if(strcmp(dp->d_name, ".") == 0 || strcmp(dp->d_name, "..") == 0)
			continue;

		std::string fname; 
		fname = fname + FolderName;
		fname.append(dp->d_name);
		//strcat(fname, dp->d_name);

		std::cout<<"dp = "<<fname<<std::endl;

		sample = cv::imread(fname);
		cv::resize(sample, sample_resized, input_geometry_); //resized to 227x227
		cv::Mat sample_float;
		sample_resized.convertTo(sample_float, CV_32FC3);
		cv::Mat sample_normalized;

		high_resolution_clock::time_point t1 = high_resolution_clock::now();
	  	//cv::subtract(sample_float, mean_, sample_normalized);
	 		
		// run vespa inference // 
		// print inferences ////////////////////
		channels_number = input->getTensorDesc().getDims()[1];
    		image_size = input->getTensorDesc().getDims()[3] * input->getTensorDesc().getDims()[2];
		
		for (size_t pid = 0; pid < image_size; ++pid) {
			for (size_t ch = 0; ch < channels_number; ++ch) {
                		input_data[ch * image_size + pid] = sample_resized.at<cv::Vec3b>(pid)[ch];
            		}
        	}
		// Running the request synchronously //
        
        	infer_request.Infer();
		output = infer_request.GetBlob(output_name);
		auto output_data = output->buffer().as<PrecisionTrait<Precision::FP32>::value_type*>(); 
		
		high_resolution_clock::time_point t2 = high_resolution_clock::now();
		duration<double> time_span = duration_cast<duration<double>>(t2-t1);
		cout<<"Frames processed on "<<" = "<< " took = "<< time_span.count()<<" seconds"<<endl;
	
		/*if(frame_idx % 25 == 0) {
		duration<double> time_span = duration_cast<duration<double>>(t2-t1);
		cout<<"Frames processed on "<<reid_mode<<" = " << frame_idx<< " took = "<< time_span.count()<<" seconds"<<endl; */
	}
		
		
}
